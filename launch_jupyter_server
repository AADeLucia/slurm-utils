#!/bin/bash
# A wrapper script to dynamically launch a Jupyter Notebook on Slurm,
# with options for GPU usage and specifying the notebook file.

source ~/.bashrc

# --- Self-Discovery: Find the utils directory ---
SOURCE="${BASH_SOURCE[0]}"
while [ -h "$SOURCE" ]; do
  DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null 2>&1 && pwd )"
  SOURCE="$(readlink "$SOURCE")"
  [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE"
done
UTILS_DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null 2>&1 && pwd )"

# --- Source Helpers (Relative to this script) ---
if [ -f "${UTILS_DIR}/slurm_helpers.sh" ]; then
    source "${UTILS_DIR}/slurm_helpers.sh"
else
    echo "❌ Error: slurm_helpers.sh not found in ${UTILS_DIR}"
    exit 1
fi

# --- Usage Instructions ---
usage() {
    echo "Usage: $0 [--partition <name>] [path_to_directory]"
    echo "  --partition <name>   : Optional. Preset profile (cpu, gpu, gpu-h200). Defaults to 'cpu'."
    echo "  path_to_directory    : Optional. The directory to start the Jupyter server in."
    echo "                         Defaults to the current directory if not provided."
    exit 1
}

# --- Argument Parsing ---
PARTITION_KEY="cpu"          # Default to CPU partition
PARTITION_OPTS=$(get_partition_options "cpu")
GRES_DIRECTIVE=""            # No GPU resources by default

# Loop through all command-line arguments
while [[ "$#" -gt 0 ]]; do
    case $1 in
        --partition)
            PARTITION_KEY="$2"
            RESOLVED_OPTS=$(get_partition_options "$PARTITION_KEY")

            if [ $? -ne 0 ]; then
                echo "❌ Error: Unknown partition profile '$PARTITION_KEY'"
                echo "   Check config.sh for available keys (e.g., cpu, gpu, gpu-h200)"
                exit 1
            fi

            PARTITION_OPTS="$RESOLVED_OPTS"
            # Set GPU directive if partition is GPU-based
            if [[ "$PARTITION_KEY" == gpu* ]]; then
                GRES_DIRECTIVE="#SBATCH --gres=gpu:1"
            fi
            shift 2
            ;;
        -h|--help)
            usage
            ;;
        *)
            shift
            ;;
    esac
done

# --- Set Job Name ---
JOB_NAME="jupyter"

# --- Submit the job to Slurm using a 'here document' ---
SUB_MESSAGE=$(sbatch <<EOF
#!/bin/bash
#SBATCH --job-name=${JOB_NAME}
#SBATCH --partition=${PARTITION_OPTS}
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=16G
#SBATCH --time=08:00:00
#SBATCH --output=${NOTEBOOK_LOGS}/%x.%A.log

# --- GPU RESOURCES ---
${GRES_DIRECTIVE}

PORT=\$(python -c 'import socket; s=socket.socket(); s.bind(("", 0)); print(s.getsockname()[1]); s.close()')
NODE_HOSTNAME=\${SLURM_NODELIST}

echo "================================================================="
echo "Jupyter Notebook is running on node: \${NODE_HOSTNAME}"
echo "The port is: \${PORT}"
echo ""
echo "1. From your local machine, create an SSH tunnel:"
echo "   ssh -N -L \${PORT}:\${NODE_HOSTNAME}:\${PORT} ${PUBLIC_LOGIN}"
echo ""
echo "2. Open a web browser and navigate to the URL below."
echo "================================================================="
echo ""

echo "Starting Jupyter Notebook server..."
jupyter notebook --no-browser --ip=0.0.0.0 --port=\${PORT} --notebook-dir="${HOME}"

EOF
)

# --- Extract Job ID and print confirmation ---
JOB_ID=$(parse_job_id_from_submission_message "${SUB_MESSAGE}")
echo "✅ Job ${JOB_ID} submitted to Slurm to run Jupyter Notebook on partition '${PARTITION_KEY}'."
echo "   Waiting for job to start to retrieve connection details..."

# --- Wait for job to start ---
wait_for_job_start "${JOB_ID}"
sleep 10

# --- Print log file for connection instructions ---
LOG_FILE="${NOTEBOOK_LOGS}/${JOB_NAME}.${JOB_ID}.log"
echo ""
echo "✅ Job started!"
echo "-----------------------------------------------------------------"
echo "From your local machine, create an SSH tunnel:"
grep "ssh" "${LOG_FILE}"
echo ""
echo "Open a web browser on your local machine and navigate to"
grep "127.0.0" "${LOG_FILE}" | tail -1
echo ""
echo "Access the log file for details:"
echo "${LOG_FILE}"